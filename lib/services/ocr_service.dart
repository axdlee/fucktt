import 'package:google_ml_kit/google_ml_kit.dart';
import 'dart:developer';
import 'package:flutter/services.dart';

import 'ocr_service_manager.dart';

/// OCRæ–‡æœ¬è¯†åˆ«æœåŠ¡
/// ç°åœ¨ä½œä¸ºOCRServiceManagerçš„åŒ…è£…å™¨ï¼Œä¿æŒå‘åå…¼å®¹
class OCRService {
  static OCRService? _instance;
  static OCRService get instance => _instance ??= OCRService._();
  
  OCRService._();
  
  late final TextRecognizer _textRecognizer;
  bool _isInitialized = false;
  
  // æ–°å¢ï¼šä½¿ç”¨ç»Ÿä¸€çš„OCRæœåŠ¡ç®¡ç†å™¨
  final OCRServiceManager _manager = OCRServiceManager.instance;
  
  /// åˆå§‹åŒ–OCRæœåŠ¡
  Future<void> initialize() async {
    if (_isInitialized) return;
    
    try {
      // ä¼˜å…ˆå°è¯•åˆå§‹åŒ–Google ML Kit
      _textRecognizer = TextRecognizer(script: TextRecognitionScript.chinese);
      _isInitialized = true;
      log('âœ… Google ML Kit OCRæœåŠ¡åˆå§‹åŒ–æˆåŠŸ');
    } catch (e) {
      log('âš ï¸ Google ML Kit OCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥: $e');
      log('ğŸ’¡ è¿™åœ¨å›½å†…æ˜¯æ­£å¸¸ç°è±¡ï¼Œå°†ä½¿ç”¨å›½äº§OCRæœåŠ¡ä½œä¸ºæ›¿ä»£');
      _isInitialized = false;
      throw Exception('Google ML Kit OCRæœåŠ¡åˆå§‹åŒ–å¤±è´¥');
    }
  }
  
  /// ä»å›¾ç‰‡ä¸­æå–æ–‡æœ¬
  Future<OCRResult> extractTextFromImage(Uint8List imageData) async {
    if (!_isInitialized) {
      await initialize();
    }
    
    try {
      // åˆ›å»ºInputImage
      final inputImage = InputImage.fromBytes(
        bytes: imageData,
        metadata: InputImageMetadata(
          size: Size(1080, 1920), // é»˜è®¤å±å¹•å°ºå¯¸ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦åŠ¨æ€è·å–
          rotation: InputImageRotation.rotation0deg,
          format: InputImageFormat.nv21,
          bytesPerRow: 1080,
        ),
      );
      
      // æ‰§è¡Œæ–‡æœ¬è¯†åˆ«
      final recognizedText = await _textRecognizer.processImage(inputImage);
      
      // è§£æç»“æœ
      return _parseRecognitionResult(recognizedText);
    } catch (e) {
      log('æ–‡æœ¬è¯†åˆ«å¤±è´¥: $e');
      return OCRResult(
        fullText: '',
        textBlocks: [],
        confidence: 0.0,
        language: 'zh',
      );
    }
  }
  
  /// ä»å›¾ç‰‡è·¯å¾„æå–æ–‡æœ¬
  Future<OCRResult> extractTextFromPath(String imagePath) async {
    if (!_isInitialized) {
      await initialize();
    }
    
    try {
      final inputImage = InputImage.fromFilePath(imagePath);
      final recognizedText = await _textRecognizer.processImage(inputImage);
      return _parseRecognitionResult(recognizedText);
    } catch (e) {
      log('ä»æ–‡ä»¶è¯†åˆ«æ–‡æœ¬å¤±è´¥: $e');
      return OCRResult(
        fullText: '',
        textBlocks: [],
        confidence: 0.0,
        language: 'zh',
      );
    }
  }
  
  /// æ‰¹é‡å¤„ç†å¤šå¼ å›¾ç‰‡
  Future<List<OCRResult>> extractTextFromImages(List<Uint8List> images) async {
    final results = <OCRResult>[];
    
    for (final imageData in images) {
      try {
        final result = await extractTextFromImage(imageData);
        results.add(result);
      } catch (e) {
        log('æ‰¹é‡è¯†åˆ«ä¸­çš„å›¾ç‰‡å¤„ç†å¤±è´¥: $e');
        results.add(OCRResult(
          fullText: '',
          textBlocks: [],
          confidence: 0.0,
          language: 'zh',
        ));
      }
    }
    
    return results;
  }
  
  /// è§£æè¯†åˆ«ç»“æœ
  OCRResult _parseRecognitionResult(RecognizedText recognizedText) {
    final textBlocks = <TextBlock>[];
    double totalConfidence = 0.0;
    int blockCount = 0;
    
    for (final block in recognizedText.blocks) {
      final textBlock = TextBlock(
        text: block.text,
        confidence: 0.95, // Google ML Kitä¸å†æä¾›confidenceï¼Œä½¿ç”¨é»˜è®¤é«˜ç½®ä¿¡åº¦
        boundingBox: _convertRect(block.boundingBox),
        language: _detectLanguage(block.text),
        lines: block.lines.map((line) => TextLine(
          text: line.text,
          confidence: 0.95, // é»˜è®¤ç½®ä¿¡åº¦
          boundingBox: _convertRect(line.boundingBox),
          elements: line.elements.map((element) => TextElement(
            text: element.text,
            confidence: 0.95, // é»˜è®¤ç½®ä¿¡åº¦
            boundingBox: _convertRect(element.boundingBox),
          )).toList(),
        )).toList(),
      );
      
      textBlocks.add(textBlock);
      totalConfidence += 0.95; // ä½¿ç”¨é»˜è®¤ç½®ä¿¡åº¦
      blockCount++;
    }
    
    final averageConfidence = blockCount > 0 ? totalConfidence / blockCount : 0.0;
    
    return OCRResult(
      fullText: recognizedText.text,
      textBlocks: textBlocks,
      confidence: averageConfidence,
      language: _detectLanguage(recognizedText.text),
    );
  }
  
  /// è½¬æ¢åæ ‡çŸ©å½¢
  BoundingBox _convertRect(Rect rect) {
    return BoundingBox(
      left: rect.left,
      top: rect.top,
      width: rect.width,
      height: rect.height,
    );
  }
  
  /// æ£€æµ‹æ–‡æœ¬è¯­è¨€
  String _detectLanguage(String text) {
    // ç®€å•çš„è¯­è¨€æ£€æµ‹é€»è¾‘
    final chineseRegex = RegExp(r'[\\u4e00-\\u9fff]');
    final englishRegex = RegExp(r'[a-zA-Z]');
    
    final chineseCount = chineseRegex.allMatches(text).length;
    final englishCount = englishRegex.allMatches(text).length;
    
    if (chineseCount > englishCount) {
      return 'zh';
    } else if (englishCount > 0) {
      return 'en';
    } else {
      return 'unknown';
    }
  }
  
  /// è¿‡æ»¤å’Œæ¸…ç†æ–‡æœ¬
  String cleanText(String text) {
    // ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    String cleaned = text.replaceAll(RegExp(r'\\s+'), ' ');
    
    // ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    cleaned = cleaned.replaceAll(RegExp(r'[^\\u4e00-\\u9fff\\w\\s,.!?;:\"''""()\\[\\]{}]'), '');
    
    // ç§»é™¤è¿‡çŸ­çš„è¡Œ
    final lines = cleaned.split('\n');
    final filteredLines = lines.where((line) => line.trim().length >= 2);
    
    return filteredLines.join('\n').trim();
  }
  
  /// æå–ç‰¹å®šåŒºåŸŸçš„æ–‡æœ¬
  Future<OCRResult> extractTextFromRegion(
    Uint8List imageData,
    BoundingBox region,
  ) async {
    try {
      // è¿™é‡Œåº”è¯¥å…ˆè£å‰ªå›¾ç‰‡åˆ°æŒ‡å®šåŒºåŸŸï¼Œç„¶åè¿›è¡ŒOCR
      // ç®€åŒ–å®ç°ï¼Œç›´æ¥å¯¹æ•´ä¸ªå›¾ç‰‡è¿›è¡ŒOCR
      final result = await extractTextFromImage(imageData);
      
      // è¿‡æ»¤å‡ºåœ¨æŒ‡å®šåŒºåŸŸå†…çš„æ–‡æœ¬å—
      final filteredBlocks = result.textBlocks.where((block) {
        return _isInRegion(block.boundingBox, region);
      }).toList();
      
      final filteredText = filteredBlocks.map((block) => block.text).join('\n');
      
      return OCRResult(
        fullText: filteredText,
        textBlocks: filteredBlocks,
        confidence: result.confidence,
        language: result.language,
      );
    } catch (e) {
      log('åŒºåŸŸæ–‡æœ¬æå–å¤±è´¥: $e');
      rethrow;
    }
  }
  
  /// æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦åœ¨æŒ‡å®šåŒºåŸŸå†…
  bool _isInRegion(BoundingBox box, BoundingBox region) {
    return box.left >= region.left &&
           box.top >= region.top &&
           box.left + box.width <= region.left + region.width &&
           box.top + box.height <= region.top + region.height;
  }
  
  /// è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨
  List<String> getSupportedLanguages() {
    return ['zh', 'en', 'ja', 'ko', 'fr', 'de', 'es', 'it', 'pt', 'ru'];
  }
  
  /// é‡Šæ”¾èµ„æº
  Future<void> dispose() async {
    if (_isInitialized) {
      await _textRecognizer.close();
      _isInitialized = false;
    }
  }
}

/// OCRè¯†åˆ«ç»“æœ
class OCRResult {
  final String fullText;
  final List<TextBlock> textBlocks;
  final double confidence;
  final String language;
  
  OCRResult({
    required this.fullText,
    required this.textBlocks,
    required this.confidence,
    required this.language,
  });
  
  /// è·å–æ¸…ç†åçš„æ–‡æœ¬
  String get cleanedText => OCRService.instance.cleanText(fullText);
  
  /// æ˜¯å¦ä¸ºç©ºç»“æœ
  bool get isEmpty => fullText.trim().isEmpty;
  
  /// æ–‡æœ¬å—æ•°é‡
  int get blockCount => textBlocks.length;
  
  /// è½¬æ¢ä¸ºJSON
  Map<String, dynamic> toJson() {
    return {
      'fullText': fullText,
      'textBlocks': textBlocks.map((block) => block.toJson()).toList(),
      'confidence': confidence,
      'language': language,
    };
  }
}

/// æ–‡æœ¬å—
class TextBlock {
  final String text;
  final double confidence;
  final BoundingBox boundingBox;
  final String language;
  final List<TextLine> lines;
  
  TextBlock({
    required this.text,
    required this.confidence,
    required this.boundingBox,
    required this.language,
    required this.lines,
  });
  
  Map<String, dynamic> toJson() {
    return {
      'text': text,
      'confidence': confidence,
      'boundingBox': boundingBox.toJson(),
      'language': language,
      'lines': lines.map((line) => line.toJson()).toList(),
    };
  }
}

/// æ–‡æœ¬è¡Œ
class TextLine {
  final String text;
  final double confidence;
  final BoundingBox boundingBox;
  final List<TextElement> elements;
  
  TextLine({
    required this.text,
    required this.confidence,
    required this.boundingBox,
    required this.elements,
  });
  
  Map<String, dynamic> toJson() {
    return {
      'text': text,
      'confidence': confidence,
      'boundingBox': boundingBox.toJson(),
      'elements': elements.map((element) => element.toJson()).toList(),
    };
  }
}

/// æ–‡æœ¬å…ƒç´ 
class TextElement {
  final String text;
  final double confidence;
  final BoundingBox boundingBox;
  
  TextElement({
    required this.text,
    required this.confidence,
    required this.boundingBox,
  });
  
  Map<String, dynamic> toJson() {
    return {
      'text': text,
      'confidence': confidence,
      'boundingBox': boundingBox.toJson(),
    };
  }
}

/// è¾¹ç•Œæ¡†
class BoundingBox {
  final double left;
  final double top;
  final double width;
  final double height;
  
  BoundingBox({
    required this.left,
    required this.top,
    required this.width,
    required this.height,
  });
  
  double get right => left + width;
  double get bottom => top + height;
  
  Map<String, dynamic> toJson() {
    return {
      'left': left,
      'top': top,
      'width': width,
      'height': height,
    };
  }
}